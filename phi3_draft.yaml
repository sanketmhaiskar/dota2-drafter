base_model: microsoft/phi-3-mini-4k-instruct
model_type: phi3
tokenizer_type: AutoTokenizer

load_in_8bit: true  # Use 8-bit if needed, or set to false if you're using LoRA with full precision
trust_remote_code: true

datasets:
  - path: ./dota2trainingData/draft_train.jsonl
    type: alpaca
    validation_path: ./dota2trainingData/draft_test.jsonl

dataset_prepared_path: ./data/phi3-draft-prepared
val_set_size: 0

output_dir: ./../outputs/phi3-draft-model

sequence_len: 512
sample_packing: false
pad_to_sequence_len: false

adapter: lora  # Use 'lora' instead of 'qlora'

lora_r: 8                # LoRA rank
lora_alpha: 16           # Scaling factor
lora_dropout: 0.05       # Dropout
lora_target_modules:
lora_target_modules:
  - self_attn.o_proj
  - self_attn.qkv_proj

micro_batch_size: 2
gradient_accumulation_steps: 2
num_epochs: 1
optimizer: adamw_torch
lr_scheduler: cosine
learning_rate: 1e-4

train_on_inputs: true
group_by_length: false

bf16: true
fp16: false  # Use fp16 for mixed precision training

logging_steps: 100
save_steps: 1000
evals_per_epoch: 1
save_total_limit: 1

prompt_template: alpaca
