{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 14669,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006817097279978185,
      "grad_norm": 0.6362455487251282,
      "learning_rate": 9.900000000000001e-05,
      "loss": 1.2383,
      "step": 100
    },
    {
      "epoch": 0.01363419455995637,
      "grad_norm": 0.469481498003006,
      "learning_rate": 9.998860710321004e-05,
      "loss": 0.4567,
      "step": 200
    },
    {
      "epoch": 0.020451291839934556,
      "grad_norm": 0.3380356729030609,
      "learning_rate": 9.995397224666411e-05,
      "loss": 0.4327,
      "step": 300
    },
    {
      "epoch": 0.02726838911991274,
      "grad_norm": 0.3942601680755615,
      "learning_rate": 9.989611037200974e-05,
      "loss": 0.424,
      "step": 400
    },
    {
      "epoch": 0.034085486399890924,
      "grad_norm": 0.5808297991752625,
      "learning_rate": 9.981504838318973e-05,
      "loss": 0.4187,
      "step": 500
    },
    {
      "epoch": 0.04090258367986911,
      "grad_norm": 0.49071744084358215,
      "learning_rate": 9.971082397146654e-05,
      "loss": 0.4049,
      "step": 600
    },
    {
      "epoch": 0.0477196809598473,
      "grad_norm": 0.48416322469711304,
      "learning_rate": 9.958348559789727e-05,
      "loss": 0.4132,
      "step": 700
    },
    {
      "epoch": 0.05453677823982548,
      "grad_norm": 0.4281178414821625,
      "learning_rate": 9.94330924708006e-05,
      "loss": 0.4,
      "step": 800
    },
    {
      "epoch": 0.06135387551980367,
      "grad_norm": 0.5350972414016724,
      "learning_rate": 9.925971451822685e-05,
      "loss": 0.4023,
      "step": 900
    },
    {
      "epoch": 0.06817097279978185,
      "grad_norm": 0.42483070492744446,
      "learning_rate": 9.906343235544372e-05,
      "loss": 0.4019,
      "step": 1000
    },
    {
      "epoch": 0.07498807007976004,
      "grad_norm": 0.4125424325466156,
      "learning_rate": 9.884433724745265e-05,
      "loss": 0.4021,
      "step": 1100
    },
    {
      "epoch": 0.08180516735973822,
      "grad_norm": 0.5006356835365295,
      "learning_rate": 9.860253106655353e-05,
      "loss": 0.3971,
      "step": 1200
    },
    {
      "epoch": 0.08862226463971641,
      "grad_norm": 0.40676039457321167,
      "learning_rate": 9.833812624497725e-05,
      "loss": 0.3923,
      "step": 1300
    },
    {
      "epoch": 0.0954393619196946,
      "grad_norm": 0.4199068248271942,
      "learning_rate": 9.805124572260832e-05,
      "loss": 0.3909,
      "step": 1400
    },
    {
      "epoch": 0.10225645919967279,
      "grad_norm": 0.46036747097969055,
      "learning_rate": 9.774202288982171e-05,
      "loss": 0.3906,
      "step": 1500
    },
    {
      "epoch": 0.10907355647965096,
      "grad_norm": 0.37812086939811707,
      "learning_rate": 9.741060152546045e-05,
      "loss": 0.3881,
      "step": 1600
    },
    {
      "epoch": 0.11589065375962915,
      "grad_norm": 0.44718271493911743,
      "learning_rate": 9.705713572998319e-05,
      "loss": 0.3923,
      "step": 1700
    },
    {
      "epoch": 0.12270775103960734,
      "grad_norm": 0.4829179048538208,
      "learning_rate": 9.668178985381212e-05,
      "loss": 0.3945,
      "step": 1800
    },
    {
      "epoch": 0.12952484831958552,
      "grad_norm": 0.3836389183998108,
      "learning_rate": 9.628473842091548e-05,
      "loss": 0.3924,
      "step": 1900
    },
    {
      "epoch": 0.1363419455995637,
      "grad_norm": 0.4187106490135193,
      "learning_rate": 9.58661660476592e-05,
      "loss": 0.3797,
      "step": 2000
    },
    {
      "epoch": 0.1431590428795419,
      "grad_norm": 0.4953797459602356,
      "learning_rate": 9.542626735696628e-05,
      "loss": 0.3821,
      "step": 2100
    },
    {
      "epoch": 0.14997614015952007,
      "grad_norm": 0.4480897784233093,
      "learning_rate": 9.496524688782321e-05,
      "loss": 0.3805,
      "step": 2200
    },
    {
      "epoch": 0.15679323743949827,
      "grad_norm": 0.468168169260025,
      "learning_rate": 9.448331900017581e-05,
      "loss": 0.3787,
      "step": 2300
    },
    {
      "epoch": 0.16361033471947645,
      "grad_norm": 0.4148504436016083,
      "learning_rate": 9.398070777525871e-05,
      "loss": 0.3837,
      "step": 2400
    },
    {
      "epoch": 0.17042743199945462,
      "grad_norm": 0.39984801411628723,
      "learning_rate": 9.34576469114045e-05,
      "loss": 0.3778,
      "step": 2500
    },
    {
      "epoch": 0.17724452927943282,
      "grad_norm": 0.37737515568733215,
      "learning_rate": 9.291437961538155e-05,
      "loss": 0.378,
      "step": 2600
    },
    {
      "epoch": 0.184061626559411,
      "grad_norm": 0.36857056617736816,
      "learning_rate": 9.235115848931047e-05,
      "loss": 0.3819,
      "step": 2700
    },
    {
      "epoch": 0.1908787238393892,
      "grad_norm": 0.3661099374294281,
      "learning_rate": 9.176824541321214e-05,
      "loss": 0.3772,
      "step": 2800
    },
    {
      "epoch": 0.19769582111936737,
      "grad_norm": 0.4628678262233734,
      "learning_rate": 9.116591142324171e-05,
      "loss": 0.3631,
      "step": 2900
    },
    {
      "epoch": 0.20451291839934557,
      "grad_norm": 0.43381568789482117,
      "learning_rate": 9.05444365856655e-05,
      "loss": 0.3763,
      "step": 3000
    },
    {
      "epoch": 0.21133001567932375,
      "grad_norm": 0.42563727498054504,
      "learning_rate": 8.990410986663887e-05,
      "loss": 0.3707,
      "step": 3100
    },
    {
      "epoch": 0.21814711295930192,
      "grad_norm": 0.4201096296310425,
      "learning_rate": 8.924522899784617e-05,
      "loss": 0.3721,
      "step": 3200
    },
    {
      "epoch": 0.22496421023928012,
      "grad_norm": 0.4942415952682495,
      "learning_rate": 8.856810033806499e-05,
      "loss": 0.3716,
      "step": 3300
    },
    {
      "epoch": 0.2317813075192583,
      "grad_norm": 0.43233489990234375,
      "learning_rate": 8.787303873071883e-05,
      "loss": 0.3734,
      "step": 3400
    },
    {
      "epoch": 0.2385984047992365,
      "grad_norm": 0.4568372666835785,
      "learning_rate": 8.71603673574851e-05,
      "loss": 0.3697,
      "step": 3500
    },
    {
      "epoch": 0.24541550207921467,
      "grad_norm": 0.41987189650535583,
      "learning_rate": 8.643041758802557e-05,
      "loss": 0.3663,
      "step": 3600
    },
    {
      "epoch": 0.25223259935919284,
      "grad_norm": 0.4371753931045532,
      "learning_rate": 8.568352882591025e-05,
      "loss": 0.3617,
      "step": 3700
    },
    {
      "epoch": 0.25904969663917105,
      "grad_norm": 0.47237545251846313,
      "learning_rate": 8.492004835080522e-05,
      "loss": 0.368,
      "step": 3800
    },
    {
      "epoch": 0.26586679391914925,
      "grad_norm": 0.4767705202102661,
      "learning_rate": 8.414033115699869e-05,
      "loss": 0.3618,
      "step": 3900
    },
    {
      "epoch": 0.2726838911991274,
      "grad_norm": 0.4690823554992676,
      "learning_rate": 8.334473978833982e-05,
      "loss": 0.3626,
      "step": 4000
    },
    {
      "epoch": 0.2795009884791056,
      "grad_norm": 0.43310412764549255,
      "learning_rate": 8.253364416966736e-05,
      "loss": 0.3538,
      "step": 4100
    },
    {
      "epoch": 0.2863180857590838,
      "grad_norm": 0.5058174729347229,
      "learning_rate": 8.170742143480618e-05,
      "loss": 0.3623,
      "step": 4200
    },
    {
      "epoch": 0.29313518303906194,
      "grad_norm": 0.48894158005714417,
      "learning_rate": 8.08664557512121e-05,
      "loss": 0.3634,
      "step": 4300
    },
    {
      "epoch": 0.29995228031904014,
      "grad_norm": 0.46179109811782837,
      "learning_rate": 8.001113814134605e-05,
      "loss": 0.3587,
      "step": 4400
    },
    {
      "epoch": 0.30676937759901834,
      "grad_norm": 0.5116376280784607,
      "learning_rate": 7.9141866300861e-05,
      "loss": 0.3587,
      "step": 4500
    },
    {
      "epoch": 0.31358647487899655,
      "grad_norm": 0.5736490488052368,
      "learning_rate": 7.825904441368615e-05,
      "loss": 0.3554,
      "step": 4600
    },
    {
      "epoch": 0.3204035721589747,
      "grad_norm": 0.43487682938575745,
      "learning_rate": 7.736308296409407e-05,
      "loss": 0.3572,
      "step": 4700
    },
    {
      "epoch": 0.3272206694389529,
      "grad_norm": 0.5504313111305237,
      "learning_rate": 7.645439854583853e-05,
      "loss": 0.3483,
      "step": 4800
    },
    {
      "epoch": 0.3340377667189311,
      "grad_norm": 0.47162678837776184,
      "learning_rate": 7.553341366845155e-05,
      "loss": 0.3607,
      "step": 4900
    },
    {
      "epoch": 0.34085486399890924,
      "grad_norm": 0.5310113430023193,
      "learning_rate": 7.460055656078991e-05,
      "loss": 0.3495,
      "step": 5000
    },
    {
      "epoch": 0.34767196127888744,
      "grad_norm": 0.4879950284957886,
      "learning_rate": 7.365626097192213e-05,
      "loss": 0.3564,
      "step": 5100
    },
    {
      "epoch": 0.35448905855886564,
      "grad_norm": 0.5859299898147583,
      "learning_rate": 7.270096596944898e-05,
      "loss": 0.3508,
      "step": 5200
    },
    {
      "epoch": 0.36130615583884385,
      "grad_norm": 0.5268958210945129,
      "learning_rate": 7.173511573535083e-05,
      "loss": 0.3417,
      "step": 5300
    },
    {
      "epoch": 0.368123253118822,
      "grad_norm": 0.6921261548995972,
      "learning_rate": 7.07591593594572e-05,
      "loss": 0.3514,
      "step": 5400
    },
    {
      "epoch": 0.3749403503988002,
      "grad_norm": 0.5851904153823853,
      "learning_rate": 6.977355063063398e-05,
      "loss": 0.3411,
      "step": 5500
    },
    {
      "epoch": 0.3817574476787784,
      "grad_norm": 0.525762677192688,
      "learning_rate": 6.877874782578617e-05,
      "loss": 0.346,
      "step": 5600
    },
    {
      "epoch": 0.38857454495875654,
      "grad_norm": 0.6181641817092896,
      "learning_rate": 6.777521349677352e-05,
      "loss": 0.3486,
      "step": 5700
    },
    {
      "epoch": 0.39539164223873474,
      "grad_norm": 0.6621494293212891,
      "learning_rate": 6.67634142553384e-05,
      "loss": 0.3479,
      "step": 5800
    },
    {
      "epoch": 0.40220873951871294,
      "grad_norm": 0.4860416352748871,
      "learning_rate": 6.574382055614637e-05,
      "loss": 0.3517,
      "step": 5900
    },
    {
      "epoch": 0.40902583679869114,
      "grad_norm": 0.5901204943656921,
      "learning_rate": 6.471690647803935e-05,
      "loss": 0.3477,
      "step": 6000
    },
    {
      "epoch": 0.4158429340786693,
      "grad_norm": 0.5985164642333984,
      "learning_rate": 6.368314950360415e-05,
      "loss": 0.3436,
      "step": 6100
    },
    {
      "epoch": 0.4226600313586475,
      "grad_norm": 0.6454530954360962,
      "learning_rate": 6.264303029715801e-05,
      "loss": 0.3517,
      "step": 6200
    },
    {
      "epoch": 0.4294771286386257,
      "grad_norm": 0.6313226819038391,
      "learning_rate": 6.1597032481255e-05,
      "loss": 0.3492,
      "step": 6300
    },
    {
      "epoch": 0.43629422591860384,
      "grad_norm": 0.6268296837806702,
      "learning_rate": 6.054564241181675e-05,
      "loss": 0.3401,
      "step": 6400
    },
    {
      "epoch": 0.44311132319858204,
      "grad_norm": 0.6313799023628235,
      "learning_rate": 5.948934895199236e-05,
      "loss": 0.3373,
      "step": 6500
    },
    {
      "epoch": 0.44992842047856024,
      "grad_norm": 0.7605884671211243,
      "learning_rate": 5.842864324485243e-05,
      "loss": 0.3308,
      "step": 6600
    },
    {
      "epoch": 0.4567455177585384,
      "grad_norm": 0.8884702324867249,
      "learning_rate": 5.736401848502313e-05,
      "loss": 0.3402,
      "step": 6700
    },
    {
      "epoch": 0.4635626150385166,
      "grad_norm": 0.690059244632721,
      "learning_rate": 5.6295969689366254e-05,
      "loss": 0.342,
      "step": 6800
    },
    {
      "epoch": 0.4703797123184948,
      "grad_norm": 0.7419849038124084,
      "learning_rate": 5.5224993466812036e-05,
      "loss": 0.3346,
      "step": 6900
    },
    {
      "epoch": 0.477196809598473,
      "grad_norm": 0.5770668983459473,
      "learning_rate": 5.4151587787451616e-05,
      "loss": 0.3434,
      "step": 7000
    },
    {
      "epoch": 0.48401390687845114,
      "grad_norm": 0.7760075926780701,
      "learning_rate": 5.3076251750996844e-05,
      "loss": 0.331,
      "step": 7100
    },
    {
      "epoch": 0.49083100415842934,
      "grad_norm": 0.6738280057907104,
      "learning_rate": 5.1999485354714564e-05,
      "loss": 0.3316,
      "step": 7200
    },
    {
      "epoch": 0.49764810143840754,
      "grad_norm": 1.0576127767562866,
      "learning_rate": 5.0921789260943706e-05,
      "loss": 0.3422,
      "step": 7300
    },
    {
      "epoch": 0.5044651987183857,
      "grad_norm": 0.9690913558006287,
      "learning_rate": 4.984366456430318e-05,
      "loss": 0.3267,
      "step": 7400
    },
    {
      "epoch": 0.511282295998364,
      "grad_norm": 0.8255898356437683,
      "learning_rate": 4.876561255869868e-05,
      "loss": 0.331,
      "step": 7500
    },
    {
      "epoch": 0.5180993932783421,
      "grad_norm": 0.7995609641075134,
      "learning_rate": 4.768813450423688e-05,
      "loss": 0.3301,
      "step": 7600
    },
    {
      "epoch": 0.5249164905583202,
      "grad_norm": 0.6862738728523254,
      "learning_rate": 4.661173139415522e-05,
      "loss": 0.3343,
      "step": 7700
    },
    {
      "epoch": 0.5317335878382985,
      "grad_norm": 0.8356296420097351,
      "learning_rate": 4.5536903721876114e-05,
      "loss": 0.3357,
      "step": 7800
    },
    {
      "epoch": 0.5385506851182766,
      "grad_norm": 0.7764477729797363,
      "learning_rate": 4.4464151248293105e-05,
      "loss": 0.3303,
      "step": 7900
    },
    {
      "epoch": 0.5453677823982548,
      "grad_norm": 0.6647888422012329,
      "learning_rate": 4.339397276939798e-05,
      "loss": 0.3279,
      "step": 8000
    },
    {
      "epoch": 0.552184879678233,
      "grad_norm": 0.7936948537826538,
      "learning_rate": 4.232686588435635e-05,
      "loss": 0.3264,
      "step": 8100
    },
    {
      "epoch": 0.5590019769582112,
      "grad_norm": 0.8077018857002258,
      "learning_rate": 4.126332676413975e-05,
      "loss": 0.3276,
      "step": 8200
    },
    {
      "epoch": 0.5658190742381893,
      "grad_norm": 0.7540473341941833,
      "learning_rate": 4.020384992082187e-05,
      "loss": 0.3228,
      "step": 8300
    },
    {
      "epoch": 0.5726361715181676,
      "grad_norm": 0.8884491920471191,
      "learning_rate": 3.914892797764605e-05,
      "loss": 0.3243,
      "step": 8400
    },
    {
      "epoch": 0.5794532687981457,
      "grad_norm": 0.956364095211029,
      "learning_rate": 3.8099051439971e-05,
      "loss": 0.3194,
      "step": 8500
    },
    {
      "epoch": 0.5862703660781239,
      "grad_norm": 0.9627354145050049,
      "learning_rate": 3.7054708467201376e-05,
      "loss": 0.3125,
      "step": 8600
    },
    {
      "epoch": 0.5930874633581021,
      "grad_norm": 0.8655468225479126,
      "learning_rate": 3.601638464580909e-05,
      "loss": 0.3152,
      "step": 8700
    },
    {
      "epoch": 0.5999045606380803,
      "grad_norm": 1.101194143295288,
      "learning_rate": 3.498456276355087e-05,
      "loss": 0.3108,
      "step": 8800
    },
    {
      "epoch": 0.6067216579180585,
      "grad_norm": 0.7808655500411987,
      "learning_rate": 3.3959722584987306e-05,
      "loss": 0.3228,
      "step": 8900
    },
    {
      "epoch": 0.6135387551980367,
      "grad_norm": 0.9865267276763916,
      "learning_rate": 3.2942340628407456e-05,
      "loss": 0.3132,
      "step": 9000
    },
    {
      "epoch": 0.6203558524780148,
      "grad_norm": 0.910615861415863,
      "learning_rate": 3.193288994426284e-05,
      "loss": 0.3208,
      "step": 9100
    },
    {
      "epoch": 0.6271729497579931,
      "grad_norm": 1.061416506767273,
      "learning_rate": 3.093183989521408e-05,
      "loss": 0.318,
      "step": 9200
    },
    {
      "epoch": 0.6339900470379712,
      "grad_norm": 0.8750320672988892,
      "learning_rate": 2.993965593789193e-05,
      "loss": 0.3173,
      "step": 9300
    },
    {
      "epoch": 0.6408071443179494,
      "grad_norm": 1.1612818241119385,
      "learning_rate": 2.8956799406474812e-05,
      "loss": 0.317,
      "step": 9400
    },
    {
      "epoch": 0.6476242415979276,
      "grad_norm": 0.7325297594070435,
      "learning_rate": 2.7983727298182877e-05,
      "loss": 0.3127,
      "step": 9500
    },
    {
      "epoch": 0.6544413388779058,
      "grad_norm": 0.9594254493713379,
      "learning_rate": 2.7020892060788816e-05,
      "loss": 0.3068,
      "step": 9600
    },
    {
      "epoch": 0.6612584361578839,
      "grad_norm": 0.9639273881912231,
      "learning_rate": 2.6068741382243945e-05,
      "loss": 0.3106,
      "step": 9700
    },
    {
      "epoch": 0.6680755334378622,
      "grad_norm": 1.028085708618164,
      "learning_rate": 2.512771798251741e-05,
      "loss": 0.3114,
      "step": 9800
    },
    {
      "epoch": 0.6748926307178403,
      "grad_norm": 1.1145833730697632,
      "learning_rate": 2.4198259407745448e-05,
      "loss": 0.3099,
      "step": 9900
    },
    {
      "epoch": 0.6817097279978185,
      "grad_norm": 0.9353818297386169,
      "learning_rate": 2.328079782678624e-05,
      "loss": 0.3059,
      "step": 10000
    },
    {
      "epoch": 0.6885268252777967,
      "grad_norm": 1.2286680936813354,
      "learning_rate": 2.2375759830275062e-05,
      "loss": 0.3069,
      "step": 10100
    },
    {
      "epoch": 0.6953439225577749,
      "grad_norm": 0.8789461851119995,
      "learning_rate": 2.148356623227308e-05,
      "loss": 0.3066,
      "step": 10200
    },
    {
      "epoch": 0.702161019837753,
      "grad_norm": 1.1348925828933716,
      "learning_rate": 2.0604631874602183e-05,
      "loss": 0.3026,
      "step": 10300
    },
    {
      "epoch": 0.7089781171177313,
      "grad_norm": 0.9690189957618713,
      "learning_rate": 1.973936543395661e-05,
      "loss": 0.3071,
      "step": 10400
    },
    {
      "epoch": 0.7157952143977094,
      "grad_norm": 1.137763261795044,
      "learning_rate": 1.8888169231881207e-05,
      "loss": 0.3091,
      "step": 10500
    },
    {
      "epoch": 0.7226123116776877,
      "grad_norm": 1.1288230419158936,
      "learning_rate": 1.805143904770464e-05,
      "loss": 0.297,
      "step": 10600
    },
    {
      "epoch": 0.7294294089576658,
      "grad_norm": 1.021949052810669,
      "learning_rate": 1.722956393451448e-05,
      "loss": 0.3045,
      "step": 10700
    },
    {
      "epoch": 0.736246506237644,
      "grad_norm": 1.0745208263397217,
      "learning_rate": 1.6422926038259868e-05,
      "loss": 0.3012,
      "step": 10800
    },
    {
      "epoch": 0.7430636035176222,
      "grad_norm": 0.9459041357040405,
      "learning_rate": 1.5631900420065694e-05,
      "loss": 0.2978,
      "step": 10900
    },
    {
      "epoch": 0.7498807007976004,
      "grad_norm": 1.0537011623382568,
      "learning_rate": 1.4856854881840998e-05,
      "loss": 0.3036,
      "step": 11000
    },
    {
      "epoch": 0.7566977980775785,
      "grad_norm": 1.5510011911392212,
      "learning_rate": 1.4098149795262799e-05,
      "loss": 0.3025,
      "step": 11100
    },
    {
      "epoch": 0.7635148953575568,
      "grad_norm": 1.0715135335922241,
      "learning_rate": 1.3356137934214586e-05,
      "loss": 0.2905,
      "step": 11200
    },
    {
      "epoch": 0.7703319926375349,
      "grad_norm": 1.1298662424087524,
      "learning_rate": 1.263116431075761e-05,
      "loss": 0.3045,
      "step": 11300
    },
    {
      "epoch": 0.7771490899175131,
      "grad_norm": 1.0569138526916504,
      "learning_rate": 1.1923566014711223e-05,
      "loss": 0.294,
      "step": 11400
    },
    {
      "epoch": 0.7839661871974913,
      "grad_norm": 1.0747123956680298,
      "learning_rate": 1.1233672056916744e-05,
      "loss": 0.2978,
      "step": 11500
    },
    {
      "epoch": 0.7907832844774695,
      "grad_norm": 1.1603662967681885,
      "learning_rate": 1.0561803216257804e-05,
      "loss": 0.2995,
      "step": 11600
    },
    {
      "epoch": 0.7976003817574476,
      "grad_norm": 0.9863829016685486,
      "learning_rate": 9.908271890508342e-06,
      "loss": 0.297,
      "step": 11700
    },
    {
      "epoch": 0.8044174790374259,
      "grad_norm": 0.8513373732566833,
      "learning_rate": 9.273381951077448e-06,
      "loss": 0.2955,
      "step": 11800
    },
    {
      "epoch": 0.811234576317404,
      "grad_norm": 1.107717752456665,
      "learning_rate": 8.657428601718847e-06,
      "loss": 0.2956,
      "step": 11900
    },
    {
      "epoch": 0.8180516735973823,
      "grad_norm": 0.928332507610321,
      "learning_rate": 8.060698241270425e-06,
      "loss": 0.3038,
      "step": 12000
    },
    {
      "epoch": 0.8248687708773604,
      "grad_norm": 1.1308412551879883,
      "learning_rate": 7.4834683304878695e-06,
      "loss": 0.2943,
      "step": 12100
    },
    {
      "epoch": 0.8316858681573386,
      "grad_norm": 0.957811713218689,
      "learning_rate": 6.926007263034107e-06,
      "loss": 0.2882,
      "step": 12200
    },
    {
      "epoch": 0.8385029654373168,
      "grad_norm": 1.154239535331726,
      "learning_rate": 6.388574240684825e-06,
      "loss": 0.287,
      "step": 12300
    },
    {
      "epoch": 0.845320062717295,
      "grad_norm": 0.9680989980697632,
      "learning_rate": 5.871419152807794e-06,
      "loss": 0.2978,
      "step": 12400
    },
    {
      "epoch": 0.8521371599972731,
      "grad_norm": 1.1774526834487915,
      "learning_rate": 5.374782460172212e-06,
      "loss": 0.2995,
      "step": 12500
    },
    {
      "epoch": 0.8589542572772514,
      "grad_norm": 0.9579408764839172,
      "learning_rate": 4.898895083142063e-06,
      "loss": 0.2956,
      "step": 12600
    },
    {
      "epoch": 0.8657713545572295,
      "grad_norm": 1.0823856592178345,
      "learning_rate": 4.443978294305407e-06,
      "loss": 0.2973,
      "step": 12700
    },
    {
      "epoch": 0.8725884518372077,
      "grad_norm": 1.3153393268585205,
      "learning_rate": 4.010243615589682e-06,
      "loss": 0.2935,
      "step": 12800
    },
    {
      "epoch": 0.8794055491171859,
      "grad_norm": 1.3442094326019287,
      "learning_rate": 3.5978927199106395e-06,
      "loss": 0.295,
      "step": 12900
    },
    {
      "epoch": 0.8862226463971641,
      "grad_norm": 1.0024964809417725,
      "learning_rate": 3.20711733740085e-06,
      "loss": 0.2975,
      "step": 13000
    },
    {
      "epoch": 0.8930397436771422,
      "grad_norm": 1.180464506149292,
      "learning_rate": 2.8380991662612323e-06,
      "loss": 0.2989,
      "step": 13100
    },
    {
      "epoch": 0.8998568409571205,
      "grad_norm": 1.0748646259307861,
      "learning_rate": 2.491009788277132e-06,
      "loss": 0.2941,
      "step": 13200
    },
    {
      "epoch": 0.9066739382370986,
      "grad_norm": 1.1112204790115356,
      "learning_rate": 2.166010589038225e-06,
      "loss": 0.291,
      "step": 13300
    },
    {
      "epoch": 0.9134910355170768,
      "grad_norm": 0.9449684023857117,
      "learning_rate": 1.8632526828993191e-06,
      "loss": 0.2941,
      "step": 13400
    },
    {
      "epoch": 0.920308132797055,
      "grad_norm": 1.207271933555603,
      "learning_rate": 1.5828768427169515e-06,
      "loss": 0.2882,
      "step": 13500
    },
    {
      "epoch": 0.9271252300770332,
      "grad_norm": 1.5974611043930054,
      "learning_rate": 1.3250134343944453e-06,
      "loss": 0.2979,
      "step": 13600
    },
    {
      "epoch": 0.9339423273570114,
      "grad_norm": 1.2009164094924927,
      "learning_rate": 1.089782356265917e-06,
      "loss": 0.2879,
      "step": 13700
    },
    {
      "epoch": 0.9407594246369896,
      "grad_norm": 1.0630053281784058,
      "learning_rate": 8.772929833473164e-07,
      "loss": 0.2944,
      "step": 13800
    },
    {
      "epoch": 0.9475765219169677,
      "grad_norm": 1.17410147190094,
      "learning_rate": 6.876441164805181e-07,
      "loss": 0.2902,
      "step": 13900
    },
    {
      "epoch": 0.954393619196946,
      "grad_norm": 1.105870008468628,
      "learning_rate": 5.209239363940355e-07,
      "loss": 0.2871,
      "step": 14000
    },
    {
      "epoch": 0.9612107164769241,
      "grad_norm": 1.4018986225128174,
      "learning_rate": 3.7720996270178e-07,
      "loss": 0.2899,
      "step": 14100
    },
    {
      "epoch": 0.9680278137569023,
      "grad_norm": 1.0527303218841553,
      "learning_rate": 2.56569017858882e-07,
      "loss": 0.2913,
      "step": 14200
    },
    {
      "epoch": 0.9748449110368805,
      "grad_norm": 1.4272428750991821,
      "learning_rate": 1.5905719609138891e-07,
      "loss": 0.2927,
      "step": 14300
    },
    {
      "epoch": 0.9816620083168587,
      "grad_norm": 1.0190088748931885,
      "learning_rate": 8.471983731417332e-08,
      "loss": 0.2971,
      "step": 14400
    },
    {
      "epoch": 0.9884791055968368,
      "grad_norm": 1.0530253648757935,
      "learning_rate": 3.359150604936301e-08,
      "loss": 0.2882,
      "step": 14500
    },
    {
      "epoch": 0.9952962028768151,
      "grad_norm": 1.3306816816329956,
      "learning_rate": 5.695975354880201e-09,
      "loss": 0.2908,
      "step": 14600
    }
  ],
  "logging_steps": 100,
  "max_steps": 14669,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.7206671850038886e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
